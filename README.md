# 2022-World-Cup-Model

This repository contains two R markdown files, the first trains and validates a machine learning model which generates three probabilities; the home team winning, visiting team winning, and a draw. The second file is an example of deploying the model against the day’s games and calculates the “edge” of each pick as defined by the implied probability of the given odds to win minus the probability of winning provided by the model.  

The XGBoost model is trained on over 6000 (75%) international friendly, world cup qualifying, and world cup tournament matches between 2010-2022 using data provided via the WorldfootballR package. The model was validated on 2047 (25%) randomly selected matches during that same timeframe. After ingestion, the data required cleaning to create consistent country names, and create a dependent factorial variable called “Result”. This model was based primarily on Elo Ratings, a rating system popularized by Nate Silver and his site, https://fivethirtyeight.com/.  Originating from the world of chess, the system uses the difference in rankings between two teams as a predictor of the match. Each team is immediately debited or credited as a result of the match.  A detailed description can be found here:  https://en.wikipedia.org/wiki/Elo_rating_system#:~:text=The_Elo_rating_system_is,a_Hungarian-American_physics_professor. 

The next step was feature engineering to create a primary key to join match result data with Elo rating data taken from https://www.eloratings.net/  This data provided average and one-year change in ranks and Elo ratings, goal differential and historical records, I added variables to measure the difference between each team’s ranks and ratings, historical winning percentage, and an interactive variable between a team’s goals scored and the opponent’s goals allowed.  

The tooling used to collect the data returns game results for each team, resulting in two observations for each game; one from the perspective of the home team and the same data from that of the away team. The data needed to be transformed to combine the statistics from the home and away team into a single observation representing a single game. To do this, we create a unique ID for each game assigned to each team playing in the game, and split the data into home and away, and perform a left join on the game ID present in both data sets. 

After cleaning and feature engineering, I perform cross validation to determine the optimal number of trees to train. After fitting the model, it is validated on a random selection of games.  The overall accuracy is 57%. With 95% confidence, we can expect the overall accuracy to fall between 55 and 59 percent. I’ve also included an importance matrix to which variables are most influential in predicting winners.

The deployment file first ingests a manually created csv file which uses the latest version of the data on https://www.eloratings.net/ .  The same cleaning and feature engineering are performed to ensure the data’s format exactly matches what the model was trained on.  The output is a csv file with each game and, the model’s probability of each team winning, the implied probability from the odds, as well as the expected value of each pick. 
